/*
 * memory access sampling for hugepage-aware tiered memory management.
 */
#include <linux/kthread.h>
#include <linux/memcontrol.h>
#include <linux/mempolicy.h>
#include <linux/sched.h>
#include <linux/perf_event.h>
#include <linux/delay.h>
#include <linux/sched/cputime.h>

#include "../kernel/events/internal.h"

#include <linux/htmm.h>
#include <linux/math64.h> // æ–°å¢ï¼šå†…æ ¸ 64 ä½é™¤æ³•æ”¯æŒ

// Welford ç®—æ³•çš„å®šç‚¹æ•°ç¼©æ”¾å› å­
#define AP_SCALE_SHIFT 10 // æ”¾å¤§ 1024 å€ (2^10)

// ============================================================================
// Phase 1: Adaptive-PEBS å †æ•°æ®ç»“æ„
// ============================================================================

/**
 * heap_entry - å †ä¸­çš„å…ƒç´ 
 * @pinfo: æŒ‡å‘Pageçš„pginfoï¼Œç”¨äºè·å–Welfordæ–¹å·®æ•°æ®
 * @event_hit_count: è¯¥Eventé‡‡æ ·è¯¥Pageçš„æ¬¡æ•°ï¼ˆæœ€å°å †çš„Keyï¼‰
 */
struct heap_entry {
	pginfo_t *pinfo;
	u32 event_hit_count;
};

/**
 * event_heap - æœ€å°å †ç»“æ„ï¼Œæ¯ä¸ªEventç±»å‹ç»´æŠ¤ä¸€ä¸ª
 * @entries: åŠ¨æ€åˆ†é…çš„å †å…ƒç´ æ•°ç»„
 * @size: å½“å‰å †ä¸­çš„å…ƒç´ æ•°é‡
 * @capacity: å †çš„æœ€å¤§å®¹é‡ï¼ˆé»˜è®¤1000ï¼‰
 * @lock: è‡ªæ—‹é”ï¼Œä¿æŠ¤å †çš„å¹¶å‘è®¿é—®
 */
struct event_heap {
	struct heap_entry *entries;
	u32 size;
	u32 capacity;
	spinlock_t lock;
};

/**
 * event_type - Eventç±»å‹æšä¸¾ï¼ˆå¯¹åº”9ç§PEBSäº‹ä»¶ï¼‰
 */
enum event_type {
	EVENT_L1_HIT = 0,
	EVENT_L1_MISS,
	EVENT_L2_HIT,
	EVENT_L2_MISS,
	EVENT_L3_HIT,
	EVENT_L3_MISS,
	EVENT_DRAM_READ,
	EVENT_NVM_READ,
	EVENT_MEM_WRITE,
	EVENT_TYPE_MAX = 9
};

// å…¨å±€å †æ•°ç»„ï¼š9ä¸ªEventå„ç»´æŠ¤ä¸€ä¸ªæœ€å°å †
static struct event_heap global_event_heaps[EVENT_TYPE_MAX];

// å †å®¹é‡é…ç½®ï¼ˆåç»­å¯é€šè¿‡sysfsè°ƒæ•´ï¼‰
static u32 heap_capacity = 1000;

// ============================================================================
// Phase 3.1: è‡ªé€‚åº”å…¬å¼æ•°æ®ç»“æ„ï¼ˆAdaptive Metricsï¼‰
// ============================================================================

// å®šç‚¹æ•°ç²¾åº¦ï¼šæ‰€æœ‰åˆ†æ•°æ”¾å¤§10000å€ï¼ˆ0-10000è¡¨ç¤º0%-100%ï¼‰
#define ADAPTIVE_SCALE 10000

// ä¸‰ä¸ªç»´åº¦çš„å½’ä¸€åŒ–ä¸Šé™
#define FLUC_MAX                                                               \
	20000000000000000ULL // 2Ã—10^16ï¼Œæ³¢åŠ¨æ€§ä¸Šé™ï¼ˆè¦†ç›–P99: 1.84Ã—10^19ï¼‰
#define HIT_MAX 100 // çƒ­åº¦é˜ˆå€¼ï¼ˆevent_hit_countå¹³å‡å€¼ä¸Šé™ï¼‰
#define OVERHEAD_MAX 10000 // å¼€é”€é˜ˆå€¼ï¼ˆsample_countä¸Šé™ï¼‰

// æƒé‡ç³»æ•°ï¼ˆå®šç‚¹æ•°è¡¨ç¤ºï¼‰
static const s32 WEIGHT_VIBRATE = 4000; // 0.40 * ADAPTIVE_SCALE = 40%
static const s32 WEIGHT_HOTNESS = 5000; // 0.50 * ADAPTIVE_SCALE = 50%
static const s32 WEIGHT_OVERHEAD =
	-1000; // -0.10 * ADAPTIVE_SCALE = -10%ï¼ˆè´Ÿå‘æƒ©ç½šï¼‰

// å…¨å±€å¼€é”€è®¡æ•°å™¨ï¼šç»Ÿè®¡æ¯ä¸ªEventçš„é‡‡æ ·æ¬¡æ•°ï¼ˆç”¨äºV_overheadè®¡ç®—ï¼‰
// Phase 3.1: å»æ‰ static ä½¿ mm/htmm_core.c å¯ä»¥è®¿é—®
atomic64_t event_sample_counts[EVENT_TYPE_MAX];

// æ¯ä¸ªEventçš„è‡ªé€‚åº”æŒ‡æ ‡
struct adaptive_metrics {
	u32 vibrate_score; // æ³¢åŠ¨æ€§åˆ†æ•° [0, 10000]
	u32 hotness_score; // çƒ­åº¦åˆ†æ•° [0, 10000]
	u32 overhead_score; // å¼€é”€åˆ†æ•° [0, 10000]
	s32 V_raw; // åŸå§‹ç»¼åˆåˆ†æ•°ï¼ˆå¯èƒ½ä¸ºè´Ÿï¼‰
	u32 V_normalized; // å½’ä¸€åŒ–åˆ†æ•° [0, 10000]
	
	// Phase 3.2 æ–°å¢å­—æ®µï¼šPeriodè‡ªé€‚åº”æ›´æ–°
	u64 target_period;  // ç›®æ ‡Periodï¼ˆä»V_normæ˜ å°„å¾—åˆ°ï¼‰
	u64 current_period; // å½“å‰Periodï¼ˆä»ç¡¬ä»¶è¯»å–ï¼‰
	u64 new_period;     // EMAå¹³æ»‘åçš„æ–°Period
};

// å…¨å±€è‡ªé€‚åº”æŒ‡æ ‡æ•°ç»„ï¼ˆ9ä¸ªEventï¼‰
static struct adaptive_metrics global_adaptive_metrics[EVENT_TYPE_MAX];

// ============================================================================
// Phase 3.2: Periodè‡ªé€‚åº”æ›´æ–°é…ç½®
// ============================================================================

// EMAå¹³æ»‘ç³»æ•°ï¼ˆÎ± = 0.3ï¼‰
#define EMA_ALPHA_NUM   3      // åˆ†å­
#define EMA_ALPHA_DEN   10     // åˆ†æ¯ï¼ŒÎ± = 3/10 = 0.3

// PeriodèŒƒå›´
#define MIN_PERIOD      2000ULL    // æœ€é«˜é‡‡æ ·é¢‘ç‡ï¼ˆ2000ä¸ªäº‹ä»¶é‡‡æ ·1æ¬¡ï¼‰
#define MAX_PERIOD      200000ULL  // æœ€ä½é‡‡æ ·é¢‘ç‡ï¼ˆ200000ä¸ªäº‹ä»¶é‡‡æ ·1æ¬¡ï¼‰

// å…¨å±€å¼€é”€é¢„ç®—
#define GLOBAL_OVERHEAD_BUDGET 50000  // æ¯10ç§’æœ€å¤šé‡‡æ ·50000æ¬¡

// æ›´æ–°å‘¨æœŸ
#define ADAPTIVE_UPDATE_INTERVAL_SEC 10  // 10ç§’

// å®šæ—¶å™¨
static struct delayed_work adaptive_update_work;
static bool adaptive_timer_running = false;

// ============================================================================
// å‡½æ•°å‰å‘å£°æ˜
// ============================================================================
static int heap_init(struct event_heap *heap, u32 capacity);
static void heap_destroy(struct event_heap *heap);
static void heap_sift_up(struct event_heap *heap, u32 idx);
static void heap_sift_down(struct event_heap *heap, u32 idx);
static int heap_find(struct event_heap *heap, pginfo_t *pinfo);
static void pebs_disable(void);

// Phase 3.1: è‡ªé€‚åº”å…¬å¼å‡½æ•°å£°æ˜
static u32 calculate_vibrate_score(enum event_type type);
static u32 calculate_hotness_score(enum event_type type);
static u32 calculate_overhead_score(enum event_type type);
static void calculate_adaptive_metrics(void);
static void adaptive_metrics_init(void);

// Phase 3.2: Periodè‡ªé€‚åº”æ›´æ–°å‡½æ•°å£°æ˜
static u64 map_score_to_period(u32 v_normalized);
static u64 apply_ema_to_period(u64 current_period, u64 target_period);
static u64 get_current_period(enum event_type type);
static void update_pebs_event_period(enum event_type type, u64 new_period);
static void apply_global_overhead_control(void);
static void adaptive_update_work_handler(struct work_struct *work);
static void adaptive_timer_init(void);
static void adaptive_timer_stop(void);

struct task_struct *access_sampling = NULL;
struct perf_event ***mem_event;

static bool valid_va(unsigned long addr)
{
	if (!(addr >> (PGDIR_SHIFT + 9)) && addr != 0)
		return true;
	else
		return false;
}

static __u64 get_pebs_event(enum events e)
{
	switch (e) {
	case L1_HIT:
		return ICL_L1_HIT;
	case L1_MISS:
		return ICL_L1_MISS;
	case L2_HIT:
		return ICL_L2_HIT;
	case L2_MISS:
		return ICL_L2_MISS;
	case L3_HIT:
		return ICL_L3_HIT;
	case L3_MISS:
		return ICL_L3_MISS;
	case DRAMREAD:
		return ICL_LOCAL_DRAM;
	case NVMREAD:
		return ICL_LOCAL_PMM;
	case MEMWRITE:
		return ICL_ALL_STORES;
	default:
		return N_HTMMEVENTS;
	}
}

static int __perf_event_open(__u64 config, __u64 config1, __u64 cpu, __u64 type,
			     __u32 pid)
{
	struct perf_event_attr attr;
	struct file *file;
	int event_fd, __pid;

	memset(&attr, 0, sizeof(struct perf_event_attr));

	attr.type = PERF_TYPE_RAW;
	attr.size = sizeof(struct perf_event_attr);
	attr.config = config;
	attr.config1 = config1;
	// ä¸‰çº§é‡‡æ ·å‘¨æœŸï¼šL1/WRITE ç”¨åä¸‡çº§ï¼ŒL2 ç”¨äº”ä¸‡ï¼Œå…¶ä»–ç”¨ç™¾çº§
	if (type == L1_HIT || type == L1_MISS || type == MEMWRITE) {
		//attr.sample_period = get_sample_inst_period(0); // 100,003
		attr.sample_period = 500000; // 100,003
	} else if (type == L2_HIT || type == L2_MISS) {
		attr.sample_period = L2_SAMPLE_PERIOD; // 50,000ï¼ˆå›ºå®šï¼‰
	} else {
		//attr.sample_period = get_sample_period(0); // 199
		attr.sample_period = 5000;
	}
	attr.sample_type = PERF_SAMPLE_IP | PERF_SAMPLE_TID | PERF_SAMPLE_ADDR |
			   PERF_SAMPLE_TIME;
	attr.disabled = 0;
	attr.exclude_kernel = 1;
	attr.exclude_hv = 1;
	attr.exclude_callchain_kernel = 1;
	attr.exclude_callchain_user = 1;
	attr.precise_ip = 1;
	attr.enable_on_exec = 1;

	if (pid == 0)
		__pid = -1;
	else
		__pid = pid;

	event_fd = htmm__perf_event_open(&attr, __pid, cpu, -1, 0);
	//event_fd = htmm__perf_event_open(&attr, -1, cpu, -1, 0);
	if (event_fd <= 0) {
		printk("[error htmm__perf_event_open failure] event_fd: %d, config %llx, config1 %llx\n",
		       event_fd, config, config1);
		return -1;
	}

	file = fget(event_fd);
	if (!file) {
		printk("invalid file\n");
		return -1;
	}
	mem_event[cpu][type] = fget(event_fd)->private_data;
	return 0;
}

static int pebs_init(pid_t pid, int node)
{
	int cpu, event;

	mem_event =
		kzalloc(sizeof(struct perf_event **) * nr_cpu_ids, GFP_KERNEL);
	for_each_online_cpu (cpu) {
		mem_event[cpu] = kzalloc(
			sizeof(struct perf_event *) * N_HTMMEVENTS, GFP_KERNEL);
	}

	printk("pebs_init\n");

	for_each_online_cpu (cpu) {
		for (event = 0; event < N_HTMMEVENTS; event++) {
			if (get_pebs_event(event) == N_HTMMEVENTS) {
				mem_event[cpu][event] = NULL;
				continue;
			}

			if (__perf_event_open(get_pebs_event(event), 0, cpu,
					      event, pid))
				return -1;
			if (htmm__perf_event_init(mem_event[cpu][event],
						  BUFFER_SIZE))
				return -1;
		}
	}

	// ============================================================================
	// Phase 1: åˆå§‹åŒ–Eventå †
	// ============================================================================
	trace_printk("[Heap-Init] Initializing %d event heaps, capacity=%u\n",
		     EVENT_TYPE_MAX, heap_capacity);

	for (event = 0; event < EVENT_TYPE_MAX; event++) {
		int ret = heap_init(&global_event_heaps[event], heap_capacity);
		if (ret) {
			trace_printk(
				"[Heap-ERROR] Failed to init heap for event %d, ret=%d\n",
				event, ret);

			// æ¸…ç†å·²åˆ›å»ºçš„å †
			while (--event >= 0)
				heap_destroy(&global_event_heaps[event]);

			// æ¸…ç†PEBSèµ„æº
			pebs_disable();
			return ret;
		}

		trace_printk(
			"[Heap-Init] Event %d (%s) heap created, capacity=%u\n",
			event,
			event == EVENT_L1_HIT	 ? "L1_HIT" :
			event == EVENT_L1_MISS	 ? "L1_MISS" :
			event == EVENT_L2_HIT	 ? "L2_HIT" :
			event == EVENT_L2_MISS	 ? "L2_MISS" :
			event == EVENT_L3_HIT	 ? "L3_HIT" :
			event == EVENT_L3_MISS	 ? "L3_MISS" :
			event == EVENT_DRAM_READ ? "DRAM_READ" :
			event == EVENT_NVM_READ	 ? "NVM_READ" :
			event == EVENT_MEM_WRITE ? "MEM_WRITE" :
						   "UNKNOWN",
			heap_capacity);
	}

	trace_printk(
		"[Heap-Init] All %d event heaps initialized successfully\n",
		EVENT_TYPE_MAX);

	// ============================================================================
	// Phase 3.1: åˆå§‹åŒ–è‡ªé€‚åº”æŒ‡æ ‡ç³»ç»Ÿ
	// ============================================================================
	adaptive_metrics_init();

	return 0;
}

static void pebs_disable(void)
{
	int cpu, event;
	printk("pebs disable\n");

	/* Check if mem_event was initialized */
	if (!mem_event)
		return;

	for_each_online_cpu (cpu) {
		/* Check if this CPU's event array was allocated */
		if (!mem_event[cpu])
			continue;

		for (event = 0; event < N_HTMMEVENTS; event++) {
			if (mem_event[cpu][event])
				perf_event_disable(mem_event[cpu][event]);
		}
	}

	// ============================================================================
	// Phase 3.1: éªŒè¯è‡ªé€‚åº”æŒ‡æ ‡è®¡ç®—ï¼ˆé”€æ¯å †å‰ï¼‰
	// ============================================================================
	trace_printk(
		"[Adaptive-Trigger] Calculating metrics before heap destruction\n");
	calculate_adaptive_metrics();

	// ============================================================================
	// Phase 1: æ¸…ç†Eventå †
	// ============================================================================
	trace_printk("[Heap-Destroy] Destroying %d event heaps\n",
		     EVENT_TYPE_MAX);

	for (event = 0; event < EVENT_TYPE_MAX; event++) {
		struct event_heap *heap = &global_event_heaps[event];

		trace_printk(
			"[Heap-Destroy] Event %d (%s) heap destroyed, final_size=%u\n",
			event,
			event == EVENT_L1_HIT	 ? "L1_HIT" :
			event == EVENT_L1_MISS	 ? "L1_MISS" :
			event == EVENT_L2_HIT	 ? "L2_HIT" :
			event == EVENT_L2_MISS	 ? "L2_MISS" :
			event == EVENT_L3_HIT	 ? "L3_HIT" :
			event == EVENT_L3_MISS	 ? "L3_MISS" :
			event == EVENT_DRAM_READ ? "DRAM_READ" :
			event == EVENT_NVM_READ	 ? "NVM_READ" :
			event == EVENT_MEM_WRITE ? "MEM_WRITE" :
						   "UNKNOWN",
			heap->size);

		heap_destroy(heap);
	}

	trace_printk("[Heap-Destroy] All event heaps destroyed\n");
}

static void pebs_enable(void)
{
	int cpu, event;

	printk("pebs enable\n");
	for_each_online_cpu (cpu) {
		for (event = 0; event < N_HTMMEVENTS; event++) {
			if (mem_event[cpu][event])
				perf_event_enable(mem_event[cpu][event]);
		}
	}
}

static void pebs_update_period(uint64_t value, uint64_t inst_value)
{
	int cpu, event;

	for_each_online_cpu (cpu) {
		for (event = 0; event < N_HTMMEVENTS; event++) {
			int ret;
			if (!mem_event[cpu][event])
				continue;

			switch (event) {
			case L1_HIT:
			case L1_MISS:
			case MEMWRITE:
				ret = perf_event_period(mem_event[cpu][event],
							inst_value);
				break;
			case L2_HIT:
			case L2_MISS:
				// L2 å›ºå®šå‘¨æœŸ 50000ï¼Œä¸åŠ¨æ€è°ƒæ•´
				ret = 0;
				break;
			case L3_HIT:
			case L3_MISS:
			case DRAMREAD:
			case NVMREAD:
				ret = perf_event_period(mem_event[cpu][event],
							value);
				break;
			default:
				ret = 0;
				break;
			}

			if (ret == -EINVAL)
				printk("failed to update sample period");
		}
	}
}

/**
 * Adaptive-PEBS: æ›´æ–°é¡µé¢çš„ Welford åœ¨çº¿æ–¹å·®ï¼ˆå®šç‚¹æ•°ç‰ˆæœ¬ï¼‰
 * @pinfo: ç›®æ ‡é¡µé¢çš„ pginfo ç»“æ„æŒ‡é’ˆ
 * @now:   å½“å‰ç³»ç»Ÿæ—¶é—´æˆ³ï¼ˆæ¥è‡ª PERF_SAMPLE_TIMEï¼‰
 * 
 * ç®—æ³•è¯´æ˜ï¼š
 *   Welford åœ¨çº¿æ–¹å·®ç®—æ³•ç”¨äºè®¡ç®—è®¿é—®é—´éš”çš„æŠ–åŠ¨/æ³¢åŠ¨æ€§
 *   mean_n = mean_{n-1} + (x - mean_{n-1}) / n
 *   M2_n = M2_{n-1} + (x - mean_{n-1}) * (x - mean_n)
 *   variance = M2 / n
 * 
 * å®šç‚¹æ•°å¤„ç†ï¼š
 *   æ‰€æœ‰é—´éš”å€¼æ”¾å¤§ 1024 å€ï¼ˆå·¦ç§» 10 ä½ï¼‰ä»¥ä¿ç•™ç²¾åº¦
 * 
 * trace_printk åŸ‹ç‚¹ï¼š
 *   ç”¨äºç¦»çº¿åˆ†æå„å­—æ®µçš„æ•°å€¼èŒƒå›´ï¼Œåˆ¤æ–­ä½æ•°æ˜¯å¦åˆé€‚
 */
void update_page_fluctuation(pginfo_t *pinfo, u64 now)
{
	u64 interval; // åŸå§‹é—´éš”ï¼ˆæœªç¼©æ”¾ï¼Œå•ä½ï¼šçº³ç§’æˆ– TSC cyclesï¼‰
	u64 x_scaled; // ç¼©æ”¾åçš„é—´éš”ï¼ˆ1024 å€ï¼‰
	s64 delta, delta2; // Welford ç®—æ³•çš„ä¸¤ä¸ª delta
	u32 n; // æ ·æœ¬è®¡æ•°

	// ========== ç¬¬ 1 æ­¥ï¼šå†·å¯åŠ¨å¤„ç† ==========
	if (unlikely(pinfo->last_hit_time == 0)) {
		pinfo->last_hit_time = now;
		pinfo->adaptive_hit = 1;
		pinfo->mean_interval = 0;
		pinfo->fluctuation = 0;

		// ã€trace_printkã€‘ï¼šè®°å½•é¦–æ¬¡é‡‡æ ·
		trace_printk("[Welford-Init] pg=%px, init_time=%llu\n", pinfo,
			     now);
		return;
	}

	// ========== ç¬¬ 2 æ­¥ï¼šè®¡ç®—é—´éš”å¹¶ç¼©æ”¾ ==========
	// âš ï¸ FIX: PEBS æ—¶é—´æˆ³å¯èƒ½ä¹±åºï¼å¿½ç•¥æ—¶é—´å€’é€€çš„æ ·æœ¬
	if (unlikely(now <= pinfo->last_hit_time)) {
		// æ—¶é—´æˆ³å€’é€€æˆ–ç›¸ç­‰ï¼Œå®Œå…¨è·³è¿‡æœ¬æ¬¡æ ·æœ¬
		trace_printk(
			"[Welford-SKIP-TIME-REWIND] pg=%px, now=%llu <= last=%llu (delta=%lld)\n",
			pinfo, now, pinfo->last_hit_time,
			(s64)(now - pinfo->last_hit_time));
		// ä¸æ›´æ–° last_hit_timeï¼Œä¸å¢åŠ  adaptive_hitï¼Œå®Œå…¨å¿½ç•¥è¿™ä¸ªä¹±åºæ ·æœ¬
		return;
	}

	interval = now - pinfo->last_hit_time;
	x_scaled = interval << AP_SCALE_SHIFT; // æ”¾å¤§ 1024 å€

	// ã€trace_printkã€‘ï¼šç›‘æ§åŸå§‹é—´éš”å€¼
	// ç”¨é€”ï¼šåˆ¤æ–­ u64 æ˜¯å¦ä¼šæº¢å‡ºï¼Œè§‚å¯Ÿé—´éš”åˆ†å¸ƒ
	trace_printk(
		"[Welford-Interval] pg=%px, raw_interval=%llu, scaled=%llu\n",
		pinfo, interval, x_scaled);

	// ========== ç¬¬ 3 æ­¥ï¼šæ›´æ–°æ—¶é—´æˆ³ ==========
	pinfo->last_hit_time = now;

	// ========== ç¬¬ 4 æ­¥ï¼šæ ·æœ¬æ•°é€’å¢ ==========
	n = ++pinfo->adaptive_hit;

	// ã€trace_printkã€‘ï¼šç›‘æ§æ ·æœ¬æ•°ï¼Œåˆ¤æ–­ u32 (42äº¿) æ˜¯å¦è¶³å¤Ÿ
	// æ¯è¾¾åˆ° 2^20 (çº¦ 100 ä¸‡) çš„å€æ•°æ—¶æ‰“å°ä¸€æ¬¡é‡Œç¨‹ç¢‘
	if (unlikely((n & 0xFFFFF) == 0)) {
		trace_printk(
			"[Welford-Milestone] pg=%px, n=%u (every 1M samples)\n",
			pinfo, n);
	}

	// ========== ç¬¬ 5 æ­¥ï¼šWelford æ–¹å·®è®¡ç®— ==========

	// æ­¥éª¤ 5.1ï¼šdelta = x - mean_{n-1}
	delta = (s64)x_scaled - (s64)pinfo->mean_interval;

	// ã€trace_printkã€‘ï¼šç›‘æ§ delta1 èŒƒå›´
	// ç”¨é€”ï¼šåˆ¤æ–­ s64 æ˜¯å¦è¶³å¤Ÿï¼Œè§‚å¯Ÿæ˜¯å¦æœ‰å¼‚å¸¸å¤§çš„æ³¢åŠ¨
	trace_printk(
		"[Welford-Delta1] pg=%px, delta=%lld, x_scaled=%llu, old_mean=%llu\n",
		pinfo, delta, x_scaled, pinfo->mean_interval);

	// æ­¥éª¤ 5.2ï¼šmean_n = mean_{n-1} + delta / n
	// æ³¨æ„ï¼šå¿…é¡»ä½¿ç”¨ div_s64 è¿›è¡Œ 64 ä½æœ‰ç¬¦å·é™¤æ³•
	pinfo->mean_interval += (u64)div_s64(delta, n);

	// æ­¥éª¤ 5.3ï¼šdelta2 = x - mean_n
	delta2 = (s64)x_scaled - (s64)pinfo->mean_interval;

	// ã€trace_printkã€‘ï¼šç›‘æ§ delta2 èŒƒå›´
	trace_printk("[Welford-Delta2] pg=%px, delta2=%lld, new_mean=%llu\n",
		     pinfo, delta2, pinfo->mean_interval);

	// æ­¥éª¤ 5.4ï¼šM2_n = M2_{n-1} + delta * delta2
	// æ³¨æ„ï¼šdelta * delta2 ä¼šæ”¾å¤§åˆ° 1024*1024 = 2^20 å€
	//       å³ç§» AP_SCALE_SHIFT æ¢å¤åˆ° 1024 å€ç²¾åº¦
	pinfo->fluctuation += (u64)((delta * delta2) >> AP_SCALE_SHIFT);

	// ========== ã€æ ¸å¿ƒ trace_printkã€‘ï¼šæ±‡æ€»æ‰€æœ‰å­—æ®µæ•°å€¼ ==========
	// è¿™æ˜¯æœ€é‡è¦çš„æ—¥å¿—ï¼Œç”¨äºç¦»çº¿åˆ†æå„å­—æ®µçš„ä½æ•°æ˜¯å¦åˆé€‚
	trace_printk(
		"[Welford-Summary] pg=%px | n=%u | mean=%llu | M2=%llu | var_approx=%llu | interval=%llu\n",
		pinfo,
		pinfo->adaptive_hit, // æ ·æœ¬æ•°ï¼ˆu32ï¼Œæœ€å¤§ ~42 äº¿ï¼‰
		pinfo->mean_interval, // å‡å€¼ï¼ˆu64ï¼Œ1024 å€ç¼©æ”¾ï¼‰
		pinfo->fluctuation, // M2ï¼ˆu64ï¼Œ1024 å€ç¼©æ”¾ï¼‰
		(pinfo->adaptive_hit > 1) ?
			(pinfo->fluctuation / (pinfo->adaptive_hit - 1)) :
			0, // è¿‘ä¼¼æ ‡å‡†å·®Â²
		interval); // åŸå§‹é—´éš”ï¼ˆæœªç¼©æ”¾ï¼‰
}

static int ksamplingd(void *data)
{
	unsigned long long nr_sampled = 0, nr_dram = 0, nr_nvm = 0,
			   nr_write = 0;
	unsigned long long nr_throttled = 0, nr_lost = 0, nr_unknown = 0;
	unsigned long long nr_skip = 0;

	/* used for calculating average cpu usage of ksampled */
	struct task_struct *t = current;
	/* a unit of cputime: permil (1/1000) */
	u64 total_runtime, exec_runtime, cputime = 0;
	unsigned long total_cputime, elapsed_cputime, cur;
	/* used for periodic checks*/
	unsigned long cpucap_period = msecs_to_jiffies(15000); // 15s
	unsigned long sample_period = 0;
	unsigned long sample_inst_period = 0;
	/* report cpu/period stat */
	unsigned long trace_cputime,
		trace_period = msecs_to_jiffies(1500); // 3s
	unsigned long trace_runtime;
	/* for timeout */
	unsigned long sleep_timeout;

	/* for analytic purpose */
	unsigned long hr_dram = 0, hr_nvm = 0;

	/* orig impl: see read_sum_exec_runtime() */
	trace_runtime = total_runtime = exec_runtime = t->se.sum_exec_runtime;

	trace_cputime = total_cputime = elapsed_cputime = jiffies;
	sleep_timeout = usecs_to_jiffies(2000);

	/* TODO implements per-CPU node ksamplingd by using pg_data_t */
	/* Currently uses a single CPU node(0) */
	const struct cpumask *cpumask = cpumask_of_node(0);
	if (!cpumask_empty(cpumask))
		do_set_cpus_allowed(access_sampling, cpumask);

	while (!kthread_should_stop()) {
		int cpu, event, cond = false;

		if (htmm_mode == HTMM_NO_MIG) {
			msleep_interruptible(10000);
			continue;
		}

		for_each_online_cpu (cpu) {
			for (event = 0; event < N_HTMMEVENTS; event++) {
				do {
					struct perf_buffer *rb;
					struct perf_event_mmap_page *up;
					struct perf_event_header *ph;
					struct htmm_event *he;
					unsigned long pg_index, offset;
					int page_shift;
					__u64 head;

					if (!mem_event[cpu][event]) {
						//continue;
						break;
					}

					__sync_synchronize();

					rb = mem_event[cpu][event]->rb;
					if (!rb) {
						printk("event->rb is NULL\n");
						return -1;
					}
					/* perf_buffer is ring buffer */
					up = READ_ONCE(rb->user_page);
					head = READ_ONCE(up->data_head);
					if (head == up->data_tail) {
						if (cpu < 16)
							nr_skip++;
						//continue;
						break;
					}

					head -= up->data_tail;
					if (head >
					    (BUFFER_SIZE *
					     ksampled_max_sample_ratio / 100)) {
						cond = true;
					} else if (head <
						   (BUFFER_SIZE *
						    ksampled_min_sample_ratio /
						    100)) {
						cond = false;
					}

					/* read barrier */
					smp_rmb();

					page_shift =
						PAGE_SHIFT + page_order(rb);
					/* get address of a tail sample */
					offset = READ_ONCE(up->data_tail);
					pg_index = (offset >> page_shift) &
						   (rb->nr_pages - 1);
					offset &= (1 << page_shift) - 1;

					ph = (void *)(rb->data_pages[pg_index] +
						      offset);
					switch (ph->type) {
					case PERF_RECORD_SAMPLE:
						he = (struct htmm_event *)ph;

						// ============================================================
						// ğŸ†• æ–°å¢ï¼šä½¿ç”¨ trace_printk è®°å½• PEBS é‡‡æ ·
						// Event ç¼–å·å«ä¹‰ï¼š
						//   0=L1_HIT, 1=L1_MISS, 2=L2_HIT, 3=L2_MISS,
						//   4=L3_HIT, 5=L3_MISS, 6=DRAMREAD, 7=NVMREAD, 8=MEMWRITE
						// ============================================================

						if (!valid_va(he->addr)) {
							break;
						}
						trace_printk(
							"[PEBS] CPU=%d Event=%d PID=%u TID=%u Addr=0x%llx IP=0x%llx Time=%llu\n",
							cpu, event, he->pid,
							he->tid, he->addr,
							he->ip, he->time);
						update_pginfo(he->pid, he->addr,
							      event, he->time);
						//count_vm_event(HTMM_NR_SAMPLED);
						nr_sampled++;

						// æš‚æ—¶ä¿æŒ DRAM/NVM ç»Ÿè®¡ï¼ŒL1/L2/L3 åªè®¡å…¥ nr_sampled
						if (event == DRAMREAD) {
							nr_dram++;
							hr_dram++;
						} else if (event == NVMREAD) {
							nr_nvm++;
							hr_nvm++;
						} else if (event == MEMWRITE) {
							nr_write++;
						}
						// L1/L2/L3 äº‹ä»¶æš‚ä¸å•ç‹¬ç»Ÿè®¡
						break;
					case PERF_RECORD_THROTTLE:
					case PERF_RECORD_UNTHROTTLE:
						nr_throttled++;
						break;
					case PERF_RECORD_LOST_SAMPLES:
						nr_lost++;
						break;
					default:
						nr_unknown++;
						break;
					}
					if (nr_sampled % 500000 == 0) {
						trace_printk(
							"nr_sampled: %llu, nr_dram: %llu, nr_nvm: %llu, nr_write: %llu, nr_throttled: %llu \n",
							nr_sampled, nr_dram,
							nr_nvm, nr_write,
							nr_throttled);
						nr_dram = 0;
						nr_nvm = 0;
						nr_write = 0;
					}
					/* read, write barrier */
					smp_mb();
					WRITE_ONCE(up->data_tail,
						   up->data_tail + ph->size);
				} while (cond);
			}
		}
		/* if ksampled_soft_cpu_quota is zero, disable dynamic pebs feature */
		if (!ksampled_soft_cpu_quota)
			continue;

		/* sleep */
		schedule_timeout_interruptible(sleep_timeout);

		/* check elasped time */
		cur = jiffies;
		if ((cur - elapsed_cputime) >= cpucap_period) {
			u64 cur_runtime = t->se.sum_exec_runtime;
			exec_runtime = cur_runtime - exec_runtime; //ns
			elapsed_cputime =
				jiffies_to_usecs(cur - elapsed_cputime); //us
			if (!cputime) {
				u64 cur_cputime = div64_u64(exec_runtime,
							    elapsed_cputime);
				// EMA with the scale factor (0.2)
				cputime =
					((cur_cputime << 3) + (cputime << 1)) /
					10;
			} else
				cputime = div64_u64(exec_runtime,
						    elapsed_cputime);

			/* to prevent frequent updates, allow for a slight variation of +/- 0.5% */
			if (cputime > (ksampled_soft_cpu_quota + 5) &&
			    sample_period != pcount) {
				/* need to increase the sample period */
				/* only increase by 1 */
				unsigned long tmp1 = sample_period,
					      tmp2 = sample_inst_period;
				increase_sample_period(&sample_period,
						       &sample_inst_period);
				if (tmp1 != sample_period ||
				    tmp2 != sample_inst_period)
					pebs_update_period(
						get_sample_period(
							sample_period),
						get_sample_inst_period(
							sample_inst_period));
			} else if (cputime < (ksampled_soft_cpu_quota - 5) &&
				   sample_period) {
				unsigned long tmp1 = sample_period,
					      tmp2 = sample_inst_period;
				decrease_sample_period(&sample_period,
						       &sample_inst_period);
				if (tmp1 != sample_period ||
				    tmp2 != sample_inst_period)
					pebs_update_period(
						get_sample_period(
							sample_period),
						get_sample_inst_period(
							sample_inst_period));
			}
			/* does it need to prevent ping-pong behavior? */

			elapsed_cputime = cur;
			exec_runtime = cur_runtime;
		}

		/* This is used for reporting the sample period and cputime */
		if (cur - trace_cputime >= trace_period) {
			unsigned long hr = 0;
			u64 cur_runtime = t->se.sum_exec_runtime;
			trace_runtime = cur_runtime - trace_runtime;
			trace_cputime = jiffies_to_usecs(cur - trace_cputime);
			trace_cputime = div64_u64(trace_runtime, trace_cputime);

			if (hr_dram + hr_nvm == 0)
				hr = 0;
			else
				hr = hr_dram * 10000 / (hr_dram + hr_nvm);
			trace_printk(
				"sample_period: %lu || cputime: %lu  || hit ratio: %lu\n",
				get_sample_period(sample_period), trace_cputime,
				hr);

			hr_dram = hr_nvm = 0;
			trace_cputime = cur;
			trace_runtime = cur_runtime;
		}
	}

	total_runtime = (t->se.sum_exec_runtime) - total_runtime; // ns
	total_cputime = jiffies_to_usecs(jiffies - total_cputime); // us

	printk("nr_sampled: %llu, nr_throttled: %llu, nr_lost: %llu\n",
	       nr_sampled, nr_throttled, nr_lost);
	printk("total runtime: %llu ns, total cputime: %lu us, cpu usage: %llu\n",
	       total_runtime, total_cputime, (total_runtime) / total_cputime);

	return 0;
}

static int ksamplingd_run(void)
{
	int err = 0;

	if (!access_sampling) {
		access_sampling = kthread_run(ksamplingd, NULL, "ksamplingd");
		if (IS_ERR(access_sampling)) {
			err = PTR_ERR(access_sampling);
			access_sampling = NULL;
		}
	}
	return err;
}

// ============================================================================
// Phase 1: å †æ“ä½œå‡½æ•°
// ============================================================================

/**
 * heap_init - åˆå§‹åŒ–ä¸€ä¸ªäº‹ä»¶å †
 * @heap: è¦åˆå§‹åŒ–çš„å †ç»“æ„
 * @capacity: å †çš„æœ€å¤§å®¹é‡
 *
 * è¿”å›: 0è¡¨ç¤ºæˆåŠŸï¼Œè´Ÿæ•°è¡¨ç¤ºå¤±è´¥
 */
static int heap_init(struct event_heap *heap, u32 capacity)
{
	heap->entries =
		kmalloc_array(capacity, sizeof(struct heap_entry), GFP_KERNEL);
	if (!heap->entries) {
		trace_printk("[Heap-ERROR] Failed to allocate %u entries\n",
			     capacity);
		return -ENOMEM;
	}

	heap->size = 0;
	heap->capacity = capacity;
	spin_lock_init(&heap->lock);

	return 0;
}

/**
 * heap_destroy - é”€æ¯ä¸€ä¸ªäº‹ä»¶å †ï¼Œé‡Šæ”¾å†…å­˜
 * @heap: è¦é”€æ¯çš„å †ç»“æ„
 */
static void heap_destroy(struct event_heap *heap)
{
	if (heap->entries) {
		kfree(heap->entries);
		heap->entries = NULL;
	}
	heap->size = 0;
}

/**
 * heap_sift_up - å †çš„å‘ä¸Šè°ƒæ•´ï¼ˆç”¨äºæ’å…¥æˆ–å¢åŠ è®¡æ•°åç»´æŠ¤å †æ€§è´¨ï¼‰
 * @heap: ç›®æ ‡å †
 * @idx: éœ€è¦è°ƒæ•´çš„å…ƒç´ ç´¢å¼•
 *
 * æœ€å°å †æ€§è´¨ï¼šçˆ¶èŠ‚ç‚¹çš„event_hit_count <= å­èŠ‚ç‚¹çš„event_hit_count
 */
static void heap_sift_up(struct event_heap *heap, u32 idx)
{
	struct heap_entry temp;
	u32 parent;

	while (idx > 0) {
		parent = (idx - 1) / 2;

		// å¦‚æœå½“å‰èŠ‚ç‚¹ >= çˆ¶èŠ‚ç‚¹ï¼Œå †æ€§è´¨å·²æ»¡è¶³
		if (heap->entries[idx].event_hit_count >=
		    heap->entries[parent].event_hit_count)
			break;

		// äº¤æ¢çˆ¶å­èŠ‚ç‚¹
		temp = heap->entries[idx];
		heap->entries[idx] = heap->entries[parent];
		heap->entries[parent] = temp;

		idx = parent;
	}
}

/**
 * heap_sift_down - å †çš„å‘ä¸‹è°ƒæ•´ï¼ˆç”¨äºæ›¿æ¢å †é¡¶åç»´æŠ¤å †æ€§è´¨ï¼‰
 * @heap: ç›®æ ‡å †
 * @idx: éœ€è¦è°ƒæ•´çš„å…ƒç´ ç´¢å¼•
 */
static void heap_sift_down(struct event_heap *heap, u32 idx)
{
	struct heap_entry temp;
	u32 child, right;

	while ((child = 2 * idx + 1) < heap->size) {
		right = child + 1;

		// é€‰æ‹©è¾ƒå°çš„å­èŠ‚ç‚¹
		if (right < heap->size &&
		    heap->entries[right].event_hit_count <
			    heap->entries[child].event_hit_count) {
			child = right;
		}

		// å¦‚æœå½“å‰èŠ‚ç‚¹ <= å­èŠ‚ç‚¹ï¼Œå †æ€§è´¨å·²æ»¡è¶³
		if (heap->entries[idx].event_hit_count <=
		    heap->entries[child].event_hit_count)
			break;

		// äº¤æ¢çˆ¶å­èŠ‚ç‚¹
		temp = heap->entries[idx];
		heap->entries[idx] = heap->entries[child];
		heap->entries[child] = temp;

		idx = child;
	}
}

/**
 * heap_find - åœ¨å †ä¸­æŸ¥æ‰¾æŒ‡å®šPage
 * @heap: ç›®æ ‡å †
 * @pinfo: è¦æŸ¥æ‰¾çš„Pageçš„pginfoæŒ‡é’ˆ
 *
 * è¿”å›: å…ƒç´ ç´¢å¼•ï¼ˆ>=0ï¼‰æˆ–-1ï¼ˆæœªæ‰¾åˆ°ï¼‰
 * æ³¨æ„: O(n)å¤æ‚åº¦ï¼ŒPhase 2ä¸­å¯ä¼˜åŒ–ä¸ºå“ˆå¸Œè¡¨åŠ é€Ÿ
 */
static int heap_find(struct event_heap *heap, pginfo_t *pinfo)
{
	u32 i;

	for (i = 0; i < heap->size; i++) {
		if (heap->entries[i].pinfo == pinfo)
			return i;
	}

	return -1;
}

// ğŸ†• Adaptive-PEBS: ä»event_idè·å–event_typeæšä¸¾
static enum event_type get_event_type_from_id(int event_id)
{
	switch (event_id) {
	case 0:
		return EVENT_L1_HIT;
	case 1:
		return EVENT_L1_MISS;
	case 2:
		return EVENT_L2_HIT;
	case 3:
		return EVENT_L2_MISS;
	case 4:
		return EVENT_L3_HIT;
	case 5:
		return EVENT_L3_MISS;
	case 6:
		return EVENT_DRAM_READ;
	case 7:
		return EVENT_NVM_READ;
	case 8:
		return EVENT_MEM_WRITE;
	default:
		return EVENT_L1_HIT; // Fallback
	}
}

// ğŸ†• Adaptive-PEBS: å †çš„æ›´æ–°æˆ–æ’å…¥é€»è¾‘
static void heap_update_or_insert(struct event_heap *heap, pginfo_t *pinfo)
{
	int idx;
	unsigned long flags;

	spin_lock_irqsave(&heap->lock, flags);

	// æƒ…å†µ1: Pageå·²åœ¨å †ä¸­ â†’ å¢åŠ hit_count
	idx = heap_find(heap, pinfo);
	if (idx >= 0) {
		heap->entries[idx].event_hit_count++;
		heap_sift_up(heap, idx); // é‡æ–°æ’åº
		trace_printk("[Heap-Update] pinfo=%p new_hit=%u\n", pinfo,
			     heap->entries[idx].event_hit_count);
		spin_unlock_irqrestore(&heap->lock, flags);
		return;
	}

	// æƒ…å†µ2: å †æœªæ»¡ â†’ ç›´æ¥æ’å…¥
	if (heap->size < heap->capacity) {
		heap->entries[heap->size].pinfo = pinfo;
		heap->entries[heap->size].event_hit_count = 1;
		heap_sift_up(heap, heap->size);
		heap->size++;
		trace_printk("[Heap-Insert] pinfo=%p heap_size=%d\n", pinfo,
			     heap->size);
		spin_unlock_irqrestore(&heap->lock, flags);
		return;
	}

	// æƒ…å†µ3: å †å·²æ»¡ â†’ æ£€æŸ¥æ˜¯å¦æ›¿æ¢å †é¡¶
	if (heap->entries[0].event_hit_count < 1) {
		// åªæ›¿æ¢hit_count<1çš„å †é¡¶ï¼ˆå†·é¡µï¼‰
		heap->entries[0].pinfo = pinfo;
		heap->entries[0].event_hit_count = 1;
		heap_sift_down(heap, 0);
		trace_printk("[Heap-Replace] pinfo=%p (evict cold top)\n",
			     pinfo);
	} else {
		// å †é¡¶å·²æ˜¯çƒ­é¡µï¼Œæ–°Pageä¼˜å…ˆçº§ä¸å¤Ÿï¼Œä¸¢å¼ƒ
		trace_printk(
			"[Heap-Discard] pinfo=%p (heap full, top_hit=%u)\n",
			pinfo, heap->entries[0].event_hit_count);
	}

	spin_unlock_irqrestore(&heap->lock, flags);
}

// ğŸ†• Adaptive-PEBS: ä»PEBSé‡‡æ ·æ›´æ–°å †ï¼ˆè¢«htmm_core.cè°ƒç”¨ï¼‰
void update_event_heap_from_sample(int event_id, pginfo_t *pinfo)
{
	if (event_id < 0 || event_id >= EVENT_TYPE_MAX) {
		trace_printk("[Heap-Error] Invalid event_id=%d\n", event_id);
		return;
	}

	heap_update_or_insert(&global_event_heaps[event_id], pinfo);
}

// ============================================================================
// Phase 3.1: è‡ªé€‚åº”å…¬å¼è®¡ç®—å‡½æ•°
// ============================================================================

/**
 * calculate_vibrate_score - è®¡ç®—æ³¢åŠ¨æ€§åˆ†æ•°ï¼ˆåŸºäºWelfordæ–¹å·®ï¼‰
 * @type: Eventç±»å‹
 * 
 * ç®—æ³•ï¼š
 * 1. éå†å †ä¸­æ‰€æœ‰é¡µé¢ï¼Œç´¯åŠ fluctuation
 * 2. è®¡ç®—å¹³å‡æ³¢åŠ¨å€¼ avg_fluc = sum / count
 * 3. å½’ä¸€åŒ–ï¼šscore = min(avg_fluc * ADAPTIVE_SCALE / FLUC_MAX, ADAPTIVE_SCALE)
 * 
 * è¿”å›ï¼šæ³¢åŠ¨æ€§åˆ†æ•° [0, 10000]
 */
static u32 calculate_vibrate_score(enum event_type type)
{
	struct event_heap *heap = &global_event_heaps[type];
	u64 sum_fluctuation = 0;
	u32 count = 0;
	u32 i;
	u64 avg_fluc;
	u64 score;

	if (!heap || heap->size == 0) {
		return 0; // ç©ºå †è¿”å›0åˆ†
	}

	// éå†å †ä¸­æ‰€æœ‰é¡µé¢ï¼Œç´¯åŠ fluctuation
	for (i = 0; i < heap->size; i++) {
		struct heap_entry *entry = &heap->entries[i];
		pginfo_t *pinfo = entry->pinfo;
		if (pinfo) {
			sum_fluctuation += pinfo->fluctuation;
			count++;
		}
	}

	if (count == 0) {
		return 0;
	}

	// è®¡ç®—å¹³å‡æ³¢åŠ¨å€¼
	avg_fluc = sum_fluctuation / count;

	// å½’ä¸€åŒ–åˆ° [0, ADAPTIVE_SCALE]
	// score = min(avg_fluc * ADAPTIVE_SCALE / FLUC_MAX, ADAPTIVE_SCALE)
	if (avg_fluc >= FLUC_MAX) {
		score = ADAPTIVE_SCALE;
	} else {
		score = (avg_fluc * ADAPTIVE_SCALE) / FLUC_MAX;
	}

	return (u32)score;
}

/**
 * calculate_hotness_score - è®¡ç®—çƒ­åº¦åˆ†æ•°ï¼ˆåŸºäºhit_count + å †å¯†åº¦ï¼‰
 * @type: Eventç±»å‹
 * 
 * ç®—æ³•ï¼š
 * 1. éå†å †ä¸­æ‰€æœ‰é¡µé¢ï¼Œç´¯åŠ event_hit_count
 * 2. è®¡ç®—å¹³å‡çƒ­åº¦ avg_hit = sum / count
 * 3. è®¡ç®—å †å¯†åº¦åŠ æˆ density_bonus = (heap->size * 100) / heap->capacity
 *    - å †è¶Šæ»¡ï¼Œè¯´æ˜çƒ­é¡µè¶Šå¤šï¼ŒåŠ æˆè¶Šå¤§ï¼ˆ0-100åˆ†ï¼‰
 * 4. åŸºç¡€åˆ†æ•°ï¼šbase_score = min(avg_hit * ADAPTIVE_SCALE / HIT_MAX, ADAPTIVE_SCALE)
 * 5. æœ€ç»ˆåˆ†æ•°ï¼šscore = base_score + density_bonusï¼ˆä¸Šé™ADAPTIVE_SCALEï¼‰
 * 
 * è¿”å›ï¼šçƒ­åº¦åˆ†æ•° [0, 10000]
 */
static u32 calculate_hotness_score(enum event_type type)
{
	struct event_heap *heap = &global_event_heaps[type];
	u64 sum_hit_count = 0;
	u32 count = 0;
	u32 i;
	u64 avg_hit;
	u32 base_score;
	u32 density_bonus;
	u32 final_score;

	if (!heap || heap->size == 0) {
		return 0; // ç©ºå †è¿”å›0åˆ†
	}

	// éå†å †ä¸­æ‰€æœ‰é¡µé¢ï¼Œç´¯åŠ hit_count
	for (i = 0; i < heap->size; i++) {
		struct heap_entry *entry = &heap->entries[i];
		sum_hit_count += entry->event_hit_count;
		count++;
	}

	if (count == 0) {
		return 0;
	}

	// è®¡ç®—å¹³å‡çƒ­åº¦
	avg_hit = sum_hit_count / count;

	// åŸºç¡€åˆ†æ•°ï¼šå½’ä¸€åŒ–åˆ° [0, ADAPTIVE_SCALE]
	if (avg_hit >= HIT_MAX) {
		base_score = ADAPTIVE_SCALE;
	} else {
		base_score = (u32)((avg_hit * ADAPTIVE_SCALE) / HIT_MAX);
	}

	// å †å¯†åº¦åŠ æˆï¼šå †è¶Šæ»¡ï¼Œçƒ­é¡µè¶Šå¤šï¼ˆ0-100åˆ†ï¼‰
	// density_bonus = (heap->size * 100) / heap->capacity
	if (heap->capacity > 0) {
		density_bonus = (heap->size * 100) / heap->capacity;
	} else {
		density_bonus = 0;
	}

	// æœ€ç»ˆåˆ†æ•° = åŸºç¡€åˆ†æ•° + å¯†åº¦åŠ æˆï¼ˆä¸Šé™10000ï¼‰
	final_score = base_score + density_bonus;
	if (final_score > ADAPTIVE_SCALE) {
		final_score = ADAPTIVE_SCALE;
	}

	return final_score;
}

/**
 * calculate_overhead_score - è®¡ç®—å¼€é”€åˆ†æ•°ï¼ˆåŸºäºé‡‡æ ·è®¡æ•°ï¼‰
 * @type: Eventç±»å‹
 * 
 * ç®—æ³•ï¼š
 * 1. è¯»å–event_sample_counts[type]ï¼ˆæ¯æ¬¡update_base_pageæ—¶é€’å¢ï¼‰
 * 2. å½’ä¸€åŒ–ï¼šscore = min(count * ADAPTIVE_SCALE / OVERHEAD_MAX, ADAPTIVE_SCALE)
 * 3. æ³¨æ„ï¼šè¿™æ˜¯è´Ÿå‘æŒ‡æ ‡ï¼Œæœ€ç»ˆä¼šä¹˜ä»¥è´Ÿæƒé‡
 * 
 * è¿”å›ï¼šå¼€é”€åˆ†æ•° [0, 10000]
 */
static u32 calculate_overhead_score(enum event_type type)
{
	u64 sample_count;
	u64 score;

	// è¯»å–é‡‡æ ·è®¡æ•°
	sample_count = atomic64_read(&event_sample_counts[type]);

	// å½’ä¸€åŒ–åˆ° [0, ADAPTIVE_SCALE]
	if (sample_count >= OVERHEAD_MAX) {
		score = ADAPTIVE_SCALE;
	} else {
		score = (sample_count * ADAPTIVE_SCALE) / OVERHEAD_MAX;
	}

	return (u32)score;
}

/**
 * calculate_adaptive_metrics - ç»¼åˆè®¡ç®—æ‰€æœ‰Eventçš„è‡ªé€‚åº”åˆ†æ•°
 * 
 * Phase 3.1åŠŸèƒ½ï¼šè®¡ç®—ä¸‰ç»´åº¦åˆ†æ•°å¹¶å½’ä¸€åŒ–åˆ°[0,10000]
 * Phase 3.2ä¼šåœ¨delayed_workä¸­å‘¨æœŸæ€§è°ƒç”¨æ­¤å‡½æ•°ï¼Œæ ¹æ®åˆ†æ•°æ›´æ–°Period
 * 
 * ç®—æ³•ï¼š
 * 1. éå†9ä¸ªEventï¼Œåˆ†åˆ«è®¡ç®—ä¸‰ä¸ªç»´åº¦åˆ†æ•°
 * 2. è®¡ç®—åŸå§‹åˆ†æ•°ï¼šV_raw = Î²Â·V_vibrate + Î³Â·V_hotness + Î´Â·V_overhead
 * 3. å½’ä¸€åŒ–åˆ°[0, ADAPTIVE_SCALE]ï¼š
 *    - V_min = -1000 (æœ€å·®æƒ…å†µï¼šæŒ¯åŠ¨0ï¼Œçƒ­åº¦0ï¼Œå¼€é”€æ»¡10000)
 *    - V_max = 9000 (æœ€å¥½æƒ…å†µï¼šæŒ¯åŠ¨æ»¡10000ï¼Œçƒ­åº¦æ»¡10000ï¼Œå¼€é”€0)
 *    - V_normalized = (V_raw - V_min) * ADAPTIVE_SCALE / (V_max - V_min)
 * 4. é€šè¿‡trace_printkè¾“å‡ºæ¯ä¸ªEventçš„åˆ†æ•°ï¼ˆPhase 3.1éªŒè¯ç”¨ï¼‰
 */
static void calculate_adaptive_metrics(void)
{
	enum event_type type;
	s32 V_min = -1000; // æœ€å°å¯èƒ½åˆ†æ•° = 0*4000 + 0*5000 + 10000*(-1000)
	s32 V_max =
		9000; // æœ€å¤§å¯èƒ½åˆ†æ•° = 10000*4000 + 10000*5000 + 0*(-1000) = 90000000 / 10000 = 9000
	s32 V_range = V_max - V_min; // 10000

	trace_printk(
		"[Adaptive-Start] ===== Calculate Adaptive Metrics =====\n");

	for (type = 0; type < EVENT_TYPE_MAX; type++) {
		struct adaptive_metrics *metrics =
			&global_adaptive_metrics[type];
		u32 vibrate, hotness, overhead;
		s64 V_raw_calc;
		s32 V_raw;
		s64 V_norm_calc;

		// Step 1: è®¡ç®—ä¸‰ä¸ªç»´åº¦åˆ†æ•°
		vibrate = calculate_vibrate_score(type);
		hotness = calculate_hotness_score(type);
		overhead = calculate_overhead_score(type);

		// ä¿å­˜åˆ°metricsç»“æ„
		metrics->vibrate_score = vibrate;
		metrics->hotness_score = hotness;
		metrics->overhead_score = overhead;

		// Step 2: è®¡ç®—åŸå§‹ç»¼åˆåˆ†æ•°ï¼ˆå®šç‚¹æ•°è¿ç®—ï¼‰
		// V_raw = (Î²Â·V_vibrate + Î³Â·V_hotness + Î´Â·V_overhead) / ADAPTIVE_SCALE
		// æ³¨æ„ï¼šWEIGHT_OVERHEADæ˜¯è´Ÿæ•°
		V_raw_calc = ((s64)WEIGHT_VIBRATE * vibrate +
			      (s64)WEIGHT_HOTNESS * hotness +
			      (s64)WEIGHT_OVERHEAD * overhead) /
			     ADAPTIVE_SCALE;
		V_raw = (s32)V_raw_calc;
		metrics->V_raw = V_raw;

		// Step 3: å½’ä¸€åŒ–åˆ°[0, ADAPTIVE_SCALE]
		// V_normalized = (V_raw - V_min) * ADAPTIVE_SCALE / V_range
		if (V_raw <= V_min) {
			metrics->V_normalized = 0;
		} else if (V_raw >= V_max) {
			metrics->V_normalized = ADAPTIVE_SCALE;
		} else {
			V_norm_calc = ((s64)(V_raw - V_min) * ADAPTIVE_SCALE) /
				      V_range;
			metrics->V_normalized = (u32)V_norm_calc;
		}

		// Step 4: è¾“å‡ºè°ƒè¯•ä¿¡æ¯ï¼ˆPhase 3.1éªŒè¯ç”¨ï¼‰
		trace_printk(
			"[Adaptive-Score] Event=%d Vibrate=%u Hotness=%u Overhead=%u V_raw=%d V_norm=%u\n",
			type, vibrate, hotness, overhead, V_raw,
			metrics->V_normalized);
	}

	trace_printk("[Adaptive-Final] ===== Calculation Complete =====\n");
}

/**
 * adaptive_metrics_init - åˆå§‹åŒ–è‡ªé€‚åº”æŒ‡æ ‡ç³»ç»Ÿ
 * 
 * åœ¨pebs_initæ—¶è°ƒç”¨ï¼Œåˆå§‹åŒ–ï¼š
 * 1. event_sample_countsæ•°ç»„ï¼ˆå¼€é”€è®¡æ•°å™¨ï¼‰
 * 2. global_adaptive_metricsæ•°ç»„ï¼ˆåˆ†æ•°å­˜å‚¨ï¼‰
 */
static void adaptive_metrics_init(void)
{
	enum event_type type;

	// åˆå§‹åŒ–å¼€é”€è®¡æ•°å™¨
	for (type = 0; type < EVENT_TYPE_MAX; type++) {
		atomic64_set(&event_sample_counts[type], 0);
	}

	// åˆå§‹åŒ–è‡ªé€‚åº”æŒ‡æ ‡
	memset(global_adaptive_metrics, 0, sizeof(global_adaptive_metrics));

	trace_printk("[Adaptive-Init] Adaptive metrics system initialized\n");
}

// ============================================================================
// Phase 3.2: Periodè‡ªé€‚åº”æ›´æ–°å‡½æ•°å®ç°
// ============================================================================

/**
 * map_score_to_period - å°†å½’ä¸€åŒ–åˆ†æ•°æ˜ å°„åˆ°ç›®æ ‡Period
 * @v_normalized: å½’ä¸€åŒ–åˆ†æ•° [0, 10000]
 * 
 * è¿”å›ï¼šç›®æ ‡Period [MIN_PERIOD, MAX_PERIOD]
 * 
 * ç®—æ³•ï¼šé€†å‘çº¿æ€§æ˜ å°„
 *   V_norm=0 (0%)     â†’ Period=200,000 (æœ€ä½é¢‘ç‡)
 *   V_norm=5000 (50%) â†’ Period=101,000 (ä¸­ç­‰é¢‘ç‡)
 *   V_norm=10000(100%)â†’ Period=2,000   (æœ€é«˜é¢‘ç‡)
 * 
 * å…¬å¼ï¼šPeriod = MAX_PERIOD - (V_norm Ã— range / ADAPTIVE_SCALE)
 */
static u64 map_score_to_period(u32 v_normalized)
{
	u64 period;
	u64 range = MAX_PERIOD - MIN_PERIOD;  // 198000
	
	if (v_normalized >= ADAPTIVE_SCALE) {
		// åˆ†æ•°æ»¡åˆ† â†’ æœ€å°Periodï¼ˆæœ€é«˜é¢‘ç‡ï¼‰
		period = MIN_PERIOD;
	} else if (v_normalized == 0) {
		// åˆ†æ•°ä¸º0 â†’ æœ€å¤§Periodï¼ˆæœ€ä½é¢‘ç‡ï¼‰
		period = MAX_PERIOD;
	} else {
		// çº¿æ€§æ˜ å°„ï¼šperiod = MAX - (v_norm Ã— range / SCALE)
		period = MAX_PERIOD - ((u64)v_normalized * range / ADAPTIVE_SCALE);
	}
	
	return period;
}

int ksamplingd_init(pid_t pid, int node)
{
	int ret;

	if (access_sampling)
		return 0;

	ret = pebs_init(pid, node);
	if (ret) {
		printk("htmm__perf_event_init failure... ERROR:%d\n", ret);
		return 0;
	}

	return ksamplingd_run();
}

void ksamplingd_exit(void)
{
	if (access_sampling) {
		kthread_stop(access_sampling);
		access_sampling = NULL;
	}
	pebs_disable();
}
